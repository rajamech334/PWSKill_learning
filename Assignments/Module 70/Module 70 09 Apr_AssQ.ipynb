{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "name": ""
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "Q1. What is Bayes' theorem?\n\nAns)\n\nBayes' theorem is a mathematical formula that describes how to update the probability of a hypothesis based on new evidence. It relates the conditional and marginal probabilities of random events. It’s widely used in statistics, machine learning, and various fields for decision-making under uncertainty.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Q2. What is the formula for Bayes' theorem?\n\nAns)\n\n\n p(H|E) = P(E|H).(PH)/P(E)\n  \n              Where \n              1. P(H|E) - is the probability of the hypothesis H given the evidence E (posterior probability).\n              2. P(E|H) - is the probability of the evidence E given that H is true (likelihood).\n              3. P(H) - is the initial probability of the hypothesis H (prior probability).\n              4. P(E) - is the total probability of the evidence E (marginal likelihood).\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Q3. How is Bayes' theorem used in practice?\n\nAns)\n\nBayes' theorem is used in various fields and applications. Below are a few cases\n\n1. Medical Diagnosis: Doctors use Bayes' theorem to update the probability of a disease given new test results. For instance, if a patient tests positive for a disease, the theorem helps assess how likely the patient is to actually have the disease, considering factors like the test's accuracy and the disease's prevalence.\n\n2. Spam Filtering: Email providers use Bayesian spam filters to classify emails as spam or not. The filter calculates the probability that an email is spam based on the words it contains, updating its model as it receives more data on what constitutes spam.\n\n3. Machine Learning: In algorithms like Naive Bayes classifiers, Bayes' theorem is used for classification tasks. The algorithm predicts the class of an instance by calculating probabilities based on feature values.\n\n4. Finance: Investors use Bayes' theorem to update the probability of stock performance based on new market information, helping in risk assessment and decision-making.\n\n5. Legal Reasoning: In legal contexts, Bayes' theorem can be used to assess the probability of a suspect's guilt based on evidence presented in court, considering prior probabilities.\n\n6. Genetics: Researchers apply Bayes' theorem to determine the likelihood of genetic disorders in individuals based on family history and genetic testing results.\n\n7. A/B Testing: In marketing and web development, Bayes' theorem helps analyze the effectiveness of different strategies by updating beliefs about conversion rates based on observed outcomes.\n\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Q4. What is the relationship between Bayes' theorem and conditional probability?\n\nAns)\n\nBayes' theorem is fundamentally based on the concept of conditional probability. The theorem provides a way to reverse conditional probabilities, allowing you to update the probability of a hypothesis given new evidence.\n\nRelation between these two:\n\n1. Conditional Probability: This measures the probability of an event A occurring given that another event B has occurred. It is denoted as P(A∣B) and is defined as:\n\n        P(A|B) = P(A ∩ B)/P(B)\n\n2. Bayes' Theorem: It utilizes conditional probabilities to relate the probability of a hypothesis H given evidence E to the likelihood of the evidence given the hypothesis:\n\n       P(E|H) = P(E|H).P(H)/P(E)\n\n\n       Where :\n\n       1. P(E∣H) is the conditional probability of the evidence E occurring given that the hypothesis H is true.\n\n       2. P(H∣E) is the conditional probability of the hypothesis H given that the evidence E has been observed.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?\n\nAns)\n\nChoosing the right Naive Bayes classifier is highly depends of the nature of the data and assumption which we are willing to make out off it. A few are listed below.\n\n1. Gaussian Naive Bayes:\n\n    1.1 Use When: The features are continuous and are assumed to be normally distributed.\n\n    1.2 Description: This variant calculates the likelihood of the features based on the Gaussian distribution. It's suitable for real-valued data.\n\n2. Multinomial Naive Bayes:\n\n    2.1 Use When: The features represent counts or frequencies, such as word counts in text classification.\n\n    2.2 Description: This classifier is particularly effective for document classification tasks, where the input is a count of words (e.g., term frequency in a document).\n\n3. Bernoulli Naive Bayes:\n\n    3.1 Use When: The features are binary (e.g., whether a word occurs in a document or not).\n\n    3.2 Description: This version is suitable for binary/boolean features, such as in cases where you want to classify documents based on the presence or absence of specific words.\n\nAdditional factors to be considered:\n\n1. Data Type: The type of data you have (continuous vs. categorical vs. binary) will largely dictate the choice of classifier.\n\n2. Feature Distribution: Assess whether your features follow a normal distribution (use Gaussian), are counts (use Multinomial), or are binary (use Bernoulli).\n\n3. Performance Requirements: You might want to experiment with multiple types and validate their performance using cross-validation, focusing on metrics like accuracy, precision, recall, or F1 score based on your specific needs.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Q6. Assignment:\nYou have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive \nBayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of \neach feature value for each class:\n\nClass\t X1=1 X1=2 \tX1=3 \tX2=1 \tX2=2 \tX2=3\t X2=4\n\n\n A\t 3\t 3\t 4\t 4\t 3\t 3\t 3\n\n B\t 2\t 2\t 1\t 2\t 2\t 2\t 3\n\nAssuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance \nto belong to?\n\n\nAns)\n\nTo classify the new instance with features X1=3 and X2=4 using Naive Bayes, we need to calculate the probabilities of the instance belonging to each class (A and B) given the feature values.\n\nStep 1: Calculate the Total Counts for Each Class\n\n    1.1 For Class A:\n\nTotal instances: 3+3+4+4+3+3+3=23\n\n    1.2 For Class B:\n\nTotal instances: 2+2+1+2+2+2+3=14\n\nStep 2: Calculate the Probabilities for Each Class\nUsing the counts from the table, we can compute the likelihood for each class.\n\nFor Class A: \n    1. P(X1 = 3|A) = 4/23\n    2. P(X2 = 4|A) = 3/23\n\nFor Class B:\n    1. P(X1 = 3|B) = 1/14\n    2. P(X2 = 4|B) = 3/14\n\nStep 3: Calculate the Posterior Probabilities\n\n    Since we assume equal prior probabilities for both classes P(A)=P(B)=0.5.\n    \n    Finally P(A|X1=3, X2 = 4) and P(B|X1 =3, X2 =4)\n              For class A = 6/529( After computing)\n              For class B = 3/392\n\nStep 4: Normalize the Probabilities (Optional)\n\nTo compare, we can convert to a common denominator, but since we only need to compare the two, we can simplify:\n\nClass A : P(A|X1 = 3, X2 = 4) = 6/529\n\nClass B : To compare 3/392 and 6/529 we can find common denominator or directly compare thier cross products\n\nClaculating cross products\n    1. For Class A: 6 X 392 = 2352\n    2. For Class B: 3 X 529 = 1587\n\n    Based on the above results \n    P(A|X1 = 3, X2 =4) >P(B|X1 =3, X2 =4)\n    \n\nThe end results:\n    The Naive Bayes classifier would predict the new instance with features X1=3 and X2=4 to belong to Class A.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}